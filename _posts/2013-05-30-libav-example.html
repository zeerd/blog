---
layout: post
title: 利用libav（ffmpeg）读取视频文件的信息
tag: [FFmpeg,libav]
---
最近在研究libav（ffmpeg），发现网上找到的例子版本太旧了。于是对这个代码进行了一些修改，使其适用于新版本的lib。<br>
<!--break-->
同时，原版本中的frame存储成了ppm格式，实在少见，所以修改成了比较常用的jpeg。<br><br>基本上从头到尾都是抄来的，我只是进行了整合。原文见下面链接：<br>http://dranger.com/ffmpeg/tutorial01.c<br>http://blog.csdn.net/ajaxhe/article/details/7383800<br>http://blog.sina.com.cn/s/blog_6dec72a30100mntz.html<br><br>顺便说一句，这个可以实现linux下的视频文件封面（video cover）预览功能。<br><br><pre class="brush: c; gutter: true">// tutorial01.c<br>// Code based on a tutorial by Martin Bohme (boehme@inb.uni-luebeckREMOVETHIS.de)<br>// Tested on Gentoo, CVS version 5/01/07 compiled with GCC 4.1.1<br><br>// A small sample program that shows how to use libavformat and libavcodec to<br>// read video from a file.<br>//<br>// Use<br>//<br>// gcc -o tutorial01 tutorial01.c -lavformat -lavcodec -lz -lswscale -lavutil -ljpeg<br>//<br>// to build (assuming libavformat and libavcodec are correctly installed<br>// your system).<br>//<br>// Run using<br>//<br>// tutorial01 myvideofile.mpg<br>//<br>// to write the first five frames from &quot;myvideofile.mpg&quot; to disk in PPM<br>// format.<br>//<br>// modifed by emneg-zeerd at 2013-05-30<br>// suit for the new version of libav and save the frame to one more common type to use<br>// <br>// REF:<br>// http://dranger.com/ffmpeg/tutorial01.c<br>// http://blog.csdn.net/ajaxhe/article/details/7383800<br>// http://blog.sina.com.cn/s/blog_6dec72a30100mntz.html<br><br>#include &lt;stdio.h&gt;<br><br>#include &lt;libavcodec/avcodec.h&gt;<br>#include &lt;libavformat/avformat.h&gt;<br>#include &lt;libswscale/swscale.h&gt;<br>#include &lt;jerror.h&gt;<br>#include &lt;jpeglib.h&gt;<br><br><br>static int save_frame_as_jpeg(<br>    AVFrame *pFrameRGB, <br>    int width, <br>    int height, <br>    int framenum) <br>{<br>    char fname[512];<br>    struct jpeg_compress_struct cinfo;<br>    struct jpeg_error_mgr jerr;<br>    JSAMPROW row_pointer[1];<br>    int row_stride;<br>    uint8_t *buffer;<br>    FILE *fp = NULL;<br><br>    buffer = pFrameRGB-&gt;data[0];<br><br>    cinfo.err = jpeg_std_error(&amp;jerr);<br>    jpeg_create_compress(&amp;cinfo);<br><br>    sprintf(fname, &quot;frames_%x.jpg&quot;, framenum);<br>    fp = fopen(fname, &quot;wb&quot;);<br><br>    if (fp == NULL){<br>        return -1;<br>    }<br><br>    jpeg_stdio_dest(&amp;cinfo, fp);<br><br>    cinfo.image_width = width;<br>    cinfo.image_height = height;<br>    cinfo.input_components = 3;<br>    cinfo.in_color_space = JCS_RGB;<br><br>    jpeg_set_defaults(&amp;cinfo);<br><br>    jpeg_set_quality(&amp;cinfo, 80, TRUE);<br><br>    jpeg_start_compress(&amp;cinfo, TRUE);<br><br>    row_stride = width * 3;<br><br>    while (cinfo.next_scanline &lt; height)<br>    {<br>        /* jpeg_write_scanlines expects an array of pointers to scanlines.<br>        * Here the array is only one element long, but you could pass<br>        * more than one scanline at a time if that&#039;s more convenient.<br>        */<br>        row_pointer[0] = &amp;buffer[cinfo.next_scanline * row_stride];<br>        jpeg_write_scanlines(&amp;cinfo, row_pointer, 1);<br>    }<br><br>    jpeg_finish_compress(&amp;cinfo);<br>    fclose(fp);<br>    jpeg_destroy_compress(&amp;cinfo);<br>    <br>    return 0;<br><br>}<br><br><br><br>int main (int argc, char *argv[])<br>{<br>    AVFormatContext    *pFormatCtx;<br>    int                i, videoStream;<br>    AVCodecContext     *pCodecCtx;<br>    AVCodec            *pCodec;<br>    AVFrame            *pFrame; <br>    AVFrame            *pFrameRGB;<br>    AVPacket           packet;<br>    int                frameFinished;<br>    int                numBytes;<br>    uint8_t            *buffer;<br><br>    // Register all formats and codecs<br>    av_register_all();<br>    // Open video file<br>    pFormatCtx = NULL;<br>    if(avformat_open_input(&amp;pFormatCtx, argv[1], NULL, NULL)!=0){<br>        return -1;<br>    }<br><br>    // Retrieve stream information<br>    if(avformat_find_stream_info(pFormatCtx, NULL)&lt;0){<br>        return -1; <br>    }<br><br>    // Dump information about file onto standard error<br>    av_dump_format(pFormatCtx, 0, argv[1], 0);<br><br>    // Find the first video stream<br>    videoStream=-1;<br>    for(i=0; i&lt;pFormatCtx-&gt;nb_streams; i++){<br>        if(pFormatCtx-&gt;streams[i]-&gt;codec-&gt;codec_type==AVMEDIA_TYPE_VIDEO){<br>            videoStream=i;<br>            break;<br>        }<br>    }<br><br>    if(videoStream==-1){<br>        return -1; <br>    }<br><br><br>    // Get a pointer to the codec context for the video stream<br>    pCodecCtx=pFormatCtx-&gt;streams[videoStream]-&gt;codec;<br><br><br>    // Find the decoder for the video stream<br>    pCodec=avcodec_find_decoder(pCodecCtx-&gt;codec_id);<br>    if(pCodec==NULL) {<br>        return -1; // Codec not found<br>    }<br><br>    // Open codec<br>    if(avcodec_open2(pCodecCtx, pCodec, NULL)&lt;0){<br>        return -1; // <br>    }<br><br>    // Allocate video frame<br>    pFrame=avcodec_alloc_frame();<br>    if(pFrame==NULL){<br>        return -1; // <br>    }<br><br>    // Allocate an AVFrame structure<br>    pFrameRGB=avcodec_alloc_frame();<br>    if(pFrameRGB==NULL){<br>        return -1; // <br>    }<br><br>    // Determine required buffer size and allocate buffer<br>    numBytes=avpicture_get_size(<br>                AV_PIX_FMT_RGB24, <br>                pCodecCtx-&gt;width,<br>                pCodecCtx-&gt;height);<br>    buffer=(uint8_t *)av_malloc(numBytes*sizeof(uint8_t));<br>    if(buffer==NULL){<br>        return -1; // <br>    }<br><br>    // Assign appropriate parts of buffer to image planes in pFrameRGB<br>    // Note that pFrameRGB is an AVFrame, but AVFrame is a superset<br>    // of AVPicture<br>    avpicture_fill(<br>        (AVPicture *)pFrameRGB, <br>        buffer, <br>        AV_PIX_FMT_RGB24,<br>        pCodecCtx-&gt;width, <br>        pCodecCtx-&gt;height);<br><br><br>    // Read frames and save first five frames to disk<br>    i=1;<br><br>    while(av_read_frame(pFormatCtx, &amp;packet)&gt;=0) {<br>        // Is this a packet from the video stream?<br>        if(packet.stream_index==videoStream) {<br>            // Decode video frame<br>            int err = avcodec_decode_video2(<br>                            pCodecCtx, <br>                            pFrame, <br>                            &amp;frameFinished, <br>                            &amp;packet);<br><br>            // Did we get a video frame?<br>            if(frameFinished) {<br><br>                // Convert the image from its native format to RGB<br>                struct SwsContext *img_convert_ctx;<br><br>                img_convert_ctx = sws_getContext(<br>                                    pCodecCtx-&gt;width, <br>                                    pCodecCtx-&gt;height, <br>                                    pCodecCtx-&gt;pix_fmt,  <br>                                    pCodecCtx-&gt;width, <br>                                    pCodecCtx-&gt;height, <br>                                    AV_PIX_FMT_RGB24, <br>                                    SWS_BICUBIC, <br>                                    NULL, <br>                                    NULL, <br>                                    NULL);<br>                if(img_convert_ctx == NULL){<br>                    return -1;<br>                }<br><br>                sws_scale(<br>                    img_convert_ctx,<br>                    (const uint8_t * const*)pFrame-&gt;data, <br>                    pFrame-&gt;linesize, <br>                    0, <br>                    pCodecCtx-&gt;height,<br>                    pFrameRGB-&gt;data, <br>                    pFrameRGB-&gt;linesize);    <br><br>                // Save the frame to disk<br>                if(++i&lt;=5){<br>                    save_frame_as_jpeg(<br>                        pFrameRGB, <br>                        pCodecCtx-&gt;width, <br>                        pCodecCtx-&gt;height, <br>                        i);<br>                }<br>                else{<br>                    break;<br>                }<br>            }<br>        }<br><br>        // Free the packet that was allocated by av_read_frame<br>        av_free_packet(&amp;packet);<br>    }<br><br><br>    // Free the RGB image<br>    av_free(buffer);<br>    av_free(pFrameRGB);<br><br><br>    // Free the YUV frame<br>    av_free(pFrame);<br><br><br>    // Close the codec<br>    avcodec_close(pCodecCtx);<br><br><br>    // Close the video file<br>    avformat_close_input(&amp;pFormatCtx);<br><br>    return 0;<br>}</pre>
